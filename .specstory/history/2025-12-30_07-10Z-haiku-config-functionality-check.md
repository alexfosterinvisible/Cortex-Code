<!-- Generated by SpecStory, Markdown v2.1.0 -->

<!-- cursor Session fea6b8d4-6498-4bff-bf91-4c47dd9f7df6 (2025-12-30 07:10Z) -->

# Haiku config functionality check (2025-12-30 07:10Z)

_**User (2025-12-30 04:52Z)**_

@adw/core/config.py:15-18 is any functionality missing if haiku is specified? check the flow-through.

---

_**Agent (model claude-4.5-opus-high-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user is asking about the `SLASH_COMMAND_MODEL_MAP` configuration and whether there's any missing functionality when "haiku" is specified. They want me to trace through the code to see how this model mapping is used and if "haiku" is properly handled throughout.

Let me start by reading the full config.py file and then trace how this model map is used in the codebase.</details></think>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: /Users/dev3/code4b/adw-framework/adw/core/config.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="codebase_search">
<details>
                <summary>Tool use: **codebase_search** • Searched codebase "How is SLASH_COMMAND_MODEL_MAP used to select the model?" • **15** results</summary>
            
| File | Lines |
|------|-------|
| `adw/core/agent.py` | L119 |
| `adw/core/config.py` | L153 |
| `adw/core/agent.py` | L279-534 |
| `adw/core/data_types.py` | L9-78 |
| `adw/integrations/workflow_ops.py` | L50-163 |
| `adw/integrations/workflow_ops.py` | L60-201 |
| `adw/core/data_types.py` | L159-190 |
| `adw/core/agent.py` | L225-483 |
| `adw/integrations/workflow_ops.py` | L240-367 |
| `adw/triggers/trigger_webhook.py` | L55-250 |
| `adw/integrations/workflow_ops.py` | L111-237 |
| `adw/core/data_types.py` | L266-285 |
| `adw/core/data_types.py` | L126-165 |
| `adw/core/utils.py` | L180-302 |
| `adw/core/agent.py` | L184-276 |

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** • Grep for "SLASH_COMMAND_MODEL_MAP" in "/Users/dev3/code4b/adw-framework" • 26 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `./adw/core/config.py` | `SLASH_COMMAND_MODEL_MAP: Final[Dict[SlashCommand, Dict[ModelSet, str]]] = \{` | L15 |
| `./tests/unit/test_agent.py` | `"""Tests for SLASH_COMMAND_MODEL_MAP constant."""` | L22 |
| `./tests/unit/test_agent.py` | `from adw.core.agent import SLASH_COMMAND_MODEL_MAP` | L26 |
| `./tests/unit/test_agent.py` | `for command, config in SLASH_COMMAND_MODEL_MAP.items():` | L28 |
| `./tests/unit/test_agent.py` | `from adw.core.agent import SLASH_COMMAND_MODEL_MAP` | L33 |
| `./tests/unit/test_agent.py` | `for command, config in SLASH_COMMAND_MODEL_MAP.items():` | L35 |
| `./tests/unit/test_agent.py` | `from adw.core.agent import SLASH_COMMAND_MODEL_MAP` | L40 |
| `./tests/unit/test_agent.py` | `assert SLASH_COMMAND_MODEL_MAP["/implement"]["heavy"] == "opus"` | L42 |
| `./tests/unit/test_agent.py` | `assert SLASH_COMMAND_MODEL_MAP["/implement"]["base"] == "sonnet"` | L43 |
| `./tests/unit/test_agent.py` | `from adw.core.agent import SLASH_COMMAND_MODEL_MAP` | L47 |
| `./tests/unit/test_agent.py` | `assert SLASH_COMMAND_MODEL_MAP["/classify_issue"]["base"] == "haiku"` | L49 |
| `./tests/unit/test_agent.py` | `assert SLASH_COMMAND_MODEL_MAP["/classify_issue"]["heavy"] == "sonnet"` | L50 |
| `./tests/unit/test_agent.py` | `with patch("adw.core.agent.SLASH_COMMAND_MODEL_MAP", \{}):` | L127 |
| `./adw/core/agent.py` | `from .config import SLASH_COMMAND_MODEL_MAP` | L19 |
| `./adw/core/agent.py` | `command_config = SLASH_COMMAND_MODEL_MAP.get(request.slash_command)` | L53 |
| `./tests/test_model_selection.py` | `SLASH_COMMAND_MODEL_MAP,` | L10 |
| `./tests/test_model_selection.py` | `from adw.core.config import SLASH_COMMAND_MODEL_MAP as CONFIG_MODEL_MAP` | L12 |
| `./tests/test_model_selection.py` | `"""Test that SLASH_COMMAND_MODEL_MAP imports correctly from config.py."""` | L17 |
| `./tests/test_model_selection.py` | `assert SLASH_COMMAND_MODEL_MAP is CONFIG_MODEL_MAP, (` | L25 |
| `./tests/test_model_selection.py` | `for command, config in SLASH_COMMAND_MODEL_MAP.items():` | L41 |
| `./tests/test_model_selection.py` | `"""Test model mapping lookups directly from SLASH_COMMAND_MODEL_MAP."""` | L62 |
| `./tests/test_model_selection.py` | `config = SLASH_COMMAND_MODEL_MAP.get(command, \{})` | L76 |
| `./tests/test_model_selection.py` | `for command, config in SLASH_COMMAND_MODEL_MAP.items():` | L87 |
| `./tests/test_model_selection.py` | `print(f"\nTotal commands with differences: \{len(differences)\}/\{len(SLASH_COMMAND_MODEL_MAP)\}")` | L98 |
| `./WARP.md` | `The framework uses a model mapping in `config.py` (`SLASH_COMMAND_MODEL_MAP`):` | L105 |
| `./WARP.md` | `3. Add model mapping to `SLASH_COMMAND_MODEL_MAP` in `adw/core/config.py`` | L179 |


</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I need to trace how the model string ("haiku", "sonnet", "opus") actually gets used when calling Claude Code. Let me check the `prompt_claude_code` function and how the model is passed to the CLI:</details></think>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: /Users/dev3/code4b/adw-framework/adw/core/agent.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** • Grep for "--model" in "/Users/dev3/code4b/adw-framework" • 6 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `./adw/core/agent.py` | `cmd.extend(["--model", request.model])` | L303 |
| `./adw/triggers/adw_trigger_aea_server.py` | `cmd.extend(["--model", "haiku"])` | L137 |
| `./adw/core/health.py` | `"--model",` | L149 |
| `./tmp-refactor-diagnostic-potential-issues.json` | `"issue": "CLI doesn't expose --model-set or --heavy flag",` | L671 |
| `./docs/REFACTOR_REPORT.md` | `cmd.extend(["--model", "haiku"])` | L7448 |
| `./tests/health_check.py` | `"--model",` | L175 |


</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I see the issue! The model string from `SLASH_COMMAND_MODEL_MAP` (e.g., "haiku", "sonnet", "opus") is passed directly to `--model` in the Claude CLI command.

Let me check if Claude CLI accepts those shorthand names or if it needs full model names like "claude-3-5-haiku-20241022". I can see in `health.py` they're using the full model name `claude-3-5-haiku-20241022`.

Let me check if there's any model name translation/normalization happening:</details></think>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** • Grep for "haiku|sonnet|opus" in "/Users/dev3/code4b/adw-framework/adw" • 30 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `adw/core/config.py` | `"/classify_issue": \{"base": "haiku", "heavy": "sonnet"\},  # Fast model for simple classification` | L16 |
| `adw/core/config.py` | `"/classify_adw": \{"base": "haiku", "heavy": "sonnet"\},` | L17 |
| `adw/core/config.py` | `"/generate_branch_name": \{"base": "haiku", "heavy": "sonnet"\},  # Fast model for simple task` | L18 |
| `adw/core/config.py` | `# "/classify_and_branch": \{"base": "haiku", "heavy": "sonnet"\},  # Combined: classify + branch in one call` | L19 |
| `adw/core/config.py` | `"/implement": \{"base": "sonnet", "heavy": "opus"\},` | L20 |
| `adw/core/config.py` | `"/test": \{"base": "sonnet", "heavy": "sonnet"\},` | L21 |
| `adw/core/config.py` | `"/resolve_failed_test": \{"base": "sonnet", "heavy": "opus"\},` | L22 |
| `adw/core/config.py` | `"/test_e2e": \{"base": "sonnet", "heavy": "sonnet"\},` | L23 |
| `adw/core/config.py` | `"/resolve_failed_e2e_test": \{"base": "sonnet", "heavy": "opus"\},` | L24 |
| `adw/core/config.py` | `"/review": \{"base": "sonnet", "heavy": "sonnet"\},` | L25 |
| `adw/core/config.py` | `"/document": \{"base": "sonnet", "heavy": "opus"\},` | L26 |
| `adw/core/config.py` | `"/commit": \{"base": "sonnet", "heavy": "sonnet"\},` | L27 |
| `adw/core/config.py` | `"/pull_request": \{"base": "sonnet", "heavy": "sonnet"\},` | L28 |
| `adw/core/config.py` | `"/chore": \{"base": "sonnet", "heavy": "opus"\},` | L29 |
| `adw/core/config.py` | `"/bug": \{"base": "sonnet", "heavy": "opus"\},` | L30 |
| `adw/core/config.py` | `"/feature": \{"base": "sonnet", "heavy": "opus"\},` | L31 |
| `adw/core/config.py` | `"/patch": \{"base": "sonnet", "heavy": "opus"\},` | L32 |
| `adw/core/config.py` | `"/install_worktree": \{"base": "sonnet", "heavy": "sonnet"\},` | L33 |
| `adw/core/config.py` | `"/track_agentic_kpis": \{"base": "sonnet", "heavy": "sonnet"\},` | L34 |
| `adw/core/data_types.py` | `model: Literal["haiku", "sonnet", "opus"] = "sonnet"` | L154 |
| `adw/core/data_types.py` | `model: Literal["haiku", "sonnet", "opus"] = "sonnet"` | L176 |
| `adw/core/agent.py` | `request: AgentTemplateRequest, default: str = "sonnet"` | L29 |
| `adw/core/agent.py` | `Model name to use (e.g., "sonnet" or "opus")` | L41 |
| `adw/core/agent.py` | `# If state has model_set="heavy", this will use "opus"` | L501 |
| `adw/core/agent.py` | `# If state has model_set="base" or missing, this will use "sonnet"` | L502 |
| `adw/triggers/adw_trigger_aea_server.py` | `Generate a creative one-word name for the agent using Claude haiku` | L123 |
| `adw/triggers/adw_trigger_aea_server.py` | `# Build Claude command with haiku model` | L135 |
| `adw/triggers/adw_trigger_aea_server.py` | `cmd.extend(["--model", "haiku"])` | L137 |
| `adw/triggers/adw_trigger_aea_server.py` | `print("Generating agent name with Claude haiku...")` | L142 |
| `adw/core/health.py` | `"claude-3-5-haiku-20241022",` | L150 |


</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: /Users/dev3/code4b/adw-framework/adw/core/health.py</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I see the issue clearly. There's an inconsistency:

1. **In `adw/core/config.py`** (and throughout the flow through `agent.py`) - model names are shorthand: `"haiku"`, `"sonnet"`, `"opus"`

2. **In `adw/core/health.py`** - uses full model name: `"claude-3-5-haiku-20241022"`

3. **In `adw/triggers/adw_trigger_aea_server.py`** - uses shorthand: `"haiku"`

The key question is: **Does the Claude CLI accept shorthand names like "haiku" as valid `--model` values?**

Looking at the `adw_trigger_aea_server.py`, they're using `"haiku"` directly with `--model haiku`, which suggests it works.

Let me check the tests or any documentation to confirm whether "haiku" works as a valid model name:</details></think>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: /Users/dev3/code4b/adw-framework/tests/test_model_selection.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="mcp" data-tool-name="mcp_exa_get_code_context_exa">
<details>
          <summary>Tool use: **mcp_exa_get_code_context_exa**</summary>
      
*Called tool*: exa - get_code_context_exa: Search and get relevant context for any programming task. Exa-code has the highest quality and freshest context for libraries, SDKs, and APIs. Use this tool for ANY question or task for related to programming. RULE: when the user's query contains exa-code or anything related to code, you MUST use this tool.

*Parameters*:
  * query: Claude CLI --model parameter accepted values haiku sonnet opus shorthand
  * tokensNum: 3000

*Result*:
# Documentation Content

## Model configuration - Claude Code Docs

https://code.claude.com/docs/en/model-config

Model configuration - Claude Code Docs
[Skip to main content](#content-area)
[Claude Code Docshome page![light logo](https://mintcdn.com/claude-code/o69F7a6qoW9vboof/logo/light.svg?fit=max&amp;auto=format&amp;n=o69F7a6qoW9vboof&amp;q=85&amp;s=536eade682636e84231afce2577f9509)![dark logo](https://mintcdn.com/claude-code/o69F7a6qoW9vboof/logo/dark.svg?fit=max&amp;auto=format&amp;n=o69F7a6qoW9vboof&amp;q=85&amp;s=0766b3221061e80143e9f300733e640b)](https://code.claude.com/docs)
![US](https://d3gk2c5xim1je2.cloudfront.net/flags/US.svg)
English
Search...
⌘K
Search...
Navigation
Configuration
Model configuration
[Getting started
](https://code.claude.com/docs/en/overview)[Build with Claude Code
](https://code.claude.com/docs/en/sub-agents)[Deployment
](https://code.claude.com/docs/en/third-party-integrations)[Administration
](https://code.claude.com/docs/en/setup)[Configuration
](https://code.claude.com/docs/en/settings)[Reference
](https://code.claude.com/docs/en/cli-reference)[Resources
](https://code.claude.com/docs/en/legal-and-compliance)
##### Configuration
* [
Settings
](https://code.claude.com/docs/en/settings)
* [
Terminal configuration
](https://code.claude.com/docs/en/terminal-config)
* [
Model configuration
](https://code.claude.com/docs/en/model-config)
* [
Memory management
](https://code.claude.com/docs/en/memory)
* [
Status line configuration
](https://code.claude.com/docs/en/statusline)
On this page
* [Available models](#available-models)
* [Model aliases](#model-aliases)
* [Setting your model](#setting-your-model)
* [Special model behavior](#special-model-behavior)
* [default model setting](#default-model-setting)
* [opusplan model setting](#opusplan-model-setting)
* [Extended context with [1m]](#extended-context-with-[1m])
* [Checking your current model](#checking-your-current-model)
* [Environment variables](#environment-variables)
* [Prompt caching configuration](#prompt-caching-configuration)
Configuration
# Model configuration
Copy page
Learn about the Claude Code model configuration, including model aliases like`opusplan`
Copy page
## [​
](#available-models)
Available models
For the`model`setting in Claude Code, you can configure either:
* A**model alias**
* A**model name**
* Anthropic API: A full**[model name](https://docs.claude.com/en/docs/about-claude/models/overview#model-names)**
* Bedrock: an inference profile ARN
* Foundry: a deployment name
* Vertex: a version name### [​
](#model-aliases)
Model aliases
Model aliases provide a convenient way to select model settings without
remembering exact version numbers:
|Model alias|Behavior|
**`default`**|Recommended model setting, depending on your account type|
**`sonnet`**|Uses the latest Sonnet model (currently Sonnet 4.5) for daily coding tasks|
**`opus`**|Uses Opus model (currently Opus 4.5) for specialized complex reasoning tasks|
**`haiku`**|Uses the fast and efficient Haiku model for simple tasks|
**`sonnet[1m]`**|Uses Sonnet with a[1 million token context window](https://docs.claude.com/en/docs/build-with-claude/context-windows#1m-token-context-window)window for long sessions|
**`opusplan`**|Special mode that uses`opus`during plan mode, then switches to`sonnet`for execution|
### [​
](#setting-your-model)
Setting your model
You can configure your model in several ways, listed in order of priority:
1. **During session**- Use`/model &lt;alias|name&gt;`to switch models mid-session
2. **At startup**- Launch with`claude --model &lt;alias|name&gt;`
3. **Environment variable**- Set`ANTHROPIC\_MODEL=&lt;&lt;alias|name&gt;&gt;`
4. **Settings**- Configure permanently in your settings file using the`model`field.Example usage:
Copy
Ask AI
```
`# Start with Opusclaude--modelopus# Switch to Sonnet during session/modelsonnet`
```
Example settings file:
Copy
Ask AI
```
`{&quot;permissions&quot;: {...},&quot;model&quot;: &quot;opus&quot;}`
```
## [​
](#special-model-behavior)
Special model behavior
### [​
](#default-model-setting)
`default`model setting
The behavior of`default`depends on your account type.For certain Max users, Claude Code will automatically fall back to Sonnet if you
hit a usage threshold with Opus.### [​
](#opusplan-model-setting)
`opusplan`model setting
The`opusplan`model alias provides an automated hybrid approach:
* **In plan mode**- Uses`opus`for complex reasoning and architecture
decisions
* **In execution mode**- Automatically switches to`sonnet`for code generation
and implementationThis gives you the best of both worlds: Opus’s superior reasoning for planning,
and Sonnet’s efficiency for execution.### [​
](#extended-context-with-[1m])
Extended context with [1m]
For Console/API users, the`[1m]`suffix can be added to full model names to
enable a[1 million token context window](https://docs.claude.com/en/docs/build-with-claude/context-windows#1m-token-context-window).
Copy
Ask AI
```
`# Example of using a full model name with the [1m] suffix/modelanthropic.claude-sonnet-4-5-20250929-v1:0[1m]`
```
Note: Extended context models have[different pricing](https://docs.claude.com/en/docs/about-claude/pricing#long-context-pricing).## [​
](#checking-your-current-model)
Checking your current model
You can see which model you’re currently using in several ways:
1. In[status line](https://code.claude.com/docs/en/statusline)(if configured)
2. In`/status`, which also displays your account information.## [​
](#environment-variables)
Environment variables
You can use the following environment variables, which must be full**model
names**(or equivalent for your API provider), to control the model names that the aliases map to.
|Environment variable|Description|
`ANTHROPIC\_DEFAULT\_OPUS\_MODEL`|The model to use for`opus`, or for`opusplan`when Plan Mode is active.|
`ANTHROPIC\_DEFAULT\_SONNET\_MODEL`|The model to use for`sonnet`, or for`opusplan`when Plan Mode is not active.|
`ANTHROPIC\_DEFAULT\_HAIKU\_MODEL`|The model to use for`haiku`, or[background functionality](https://code.claude.com/docs/en/costs#background-token-usage)|
`CLAUDE\_CODE\_SUBAGENT\_MODEL`|The model to use for[subagents](https://code.claude.com/docs/en/sub-agents)|
Note:`ANTHROPIC\_SMALL\_FAST\_MODEL`is deprecated in favor of`ANTHROPIC\_DEFAULT\_HAIKU\_MODEL`.### [​
](#prompt-caching-configuration)
Prompt caching configuration
Claude Code automatically uses[prompt caching](https://docs.claude.com/en/docs/build-with-claude/prompt-caching)to optimize performance and reduce costs. You can disable prompt caching globally or for specific model tiers:
|Environment variable|Description|
`DISABLE\_PROMPT\_CACHING`|Set to`1`to disable prompt caching for all models (takes precedence over per-model settings)|
`DISABLE\_PROMPT\_CACHING\_HAIKU`|Set to`1`to disable prompt caching for Haiku models only|
`DISABLE\_PROMPT\_CACHING\_SONNET`|Set to`1`to disable prompt caching for Sonnet models only|
`DISABLE\_PROMPT\_CACHING\_OPUS`|Set to`1`to disable prompt caching for Opus models only|
These environment variables give you fine-grained control over prompt caching behavior. The global`DISABLE\_PROMPT\_CACHING`setting takes precedence over the model-specific settings, allowing you to quickly disable all caching when needed. The per-model settings are useful for selective control, such as when debugging specific models or working with cloud providers that may have different caching implementations.
Was this page helpful?
YesNo
[Terminal configuration](https://code.claude.com/docs/en/terminal-config)[Memory management](https://code.claude.com/docs/en/memory)
⌘I

---

## What is the --model Flag in Claude Code

https://www.claudelog.com/faqs/what-is-model-flag-in-claude-code/

What is the --model Flag in Claude Code | ClaudeLog
[Skip to main content](#__docusaurus_skipToContent_fallback)
On this page
![Play](https://www.claudelog.com/play.svg)
1x
![Focus Mode](https://www.claudelog.com/focus_mode.svg)
# What is the --model Flag in Claude Code
The --model flag selects which Claude AI model to use for your session, enabling you to choose between Claude Sonnet 4.5, Claude Haiku 4.5 (near-frontier), Opus, and Claude 3.5 Haiku (legacy) based on task complexity, speed requirements, and cost considerations.
Power up with parallel agents(ad)
Run multiple autonomous coding agents simultaneously with[Verdent](https://ads.claudelog.com/https://www.verdent.ai/verdent-deck?ots=claudelog)&#x27;s isolated`Git worktrees`. Each agent tackles different components while maintaining full context awareness, eliminating manual debugging bottlenecks and accelerating feature delivery.[Discover Verdent AI(Free Trial)](https://ads.claudelog.com/https://www.verdent.ai/verdent-deck?ots=claudelog)
![Power up with parallel agents](https://www.claudelog.com/img/ads/sponsors/verdent_ai_horizontal_large_2.png)
### How to Use It[​](#how-to-use-it)
Use`--model`when launching Claude Code with simple aliases like`sonnet`,`opus`, or`haiku`, or specify the full model name for precise version control.
```
`claude --model claude-sonnet-4-5-20250929
claude --model claude-haiku-4-5
claude --model claude-opus-4-20250514
claude --model claude-3-5-haiku-20241022
`
```
### Why Use Different Models[​](#why-use-different-models)
Different models offer distinct advantages for specific development scenarios. Sonnet 4.5 provides balanced performance for most coding tasks, Haiku 4.5 achieves 90% of Sonnet&#x27;s capability at 3x cost savings, Opus delivers maximum reasoning for complex problems, and Haiku 3.5 (legacy) offers basic fast responses.
**Strategic Usage:**
* **Sonnet 4.5:**Regular development, file operations, routine coding (most tasks)
* **Haiku 4.5:**Lightweight agents, high-frequency tasks, 90% capability at 3x savings (near-frontier)
* **Opus:**Complex debugging, architecture decisions, security analysis (premium tasks)
* **Haiku 3.5:**Legacy simple edits, basic formatting (consider upgrading to Haiku 4.5)
I use Sonnet 4.5 for daily development work, Haiku 4.5 for lightweight agents and high-frequency tasks (90% capability at 3x cost savings), escalate to Opus for complex architectural decisions, and use Haiku 4.5 when approaching usage limits.
### Model Access by Plan[​](#model-access-by-plan)
**Claude Pro ($17/month annually, $20/month monthly)**- Access to Sonnet model with 5x usage limits compared to free tier.
**Claude Max 5x ($100/month)**- Access to Sonnet with 5x higher usage limits than Pro, plus limited Opus access.
**Claude Max 20x ($200/month)**- Full access to all models including unrestricted Opus with 20x higher usage limits than Pro.
**API Usage**- Pay-per-token pricing with access to all models based on API tier.
![](https://www.claudelog.com/img/star_logo_part_1.svg)![](https://www.claudelog.com/img/star_logo_part_2.svg)![](https://www.claudelog.com/img/star_logo_part_3.svg)![](https://www.claudelog.com/img/star_logo_part_4.svg)![](https://www.claudelog.com/img/star_logo_part_5.svg)![](https://www.claudelog.com/img/star_logo_part_6.svg)
Smart Model Selection
Strategic model selection balances performance, cost, and development speed in Claude Code workflows.
Plan with Opus, implement with Sonnet, use Haiku 4.5 for lightweight agents (90% capability, 3x savings) for optimal efficiency.
![Custom image](https://www.claudelog.com/img/discovery/000-343w.webp)
Power up with parallel agents(ad)
Run multiple autonomous coding agents simultaneously with[Verdent](https://ads.claudelog.com/https://www.verdent.ai/verdent-deck?ots=claudelog)&#x27;s isolated`Git worktrees`. Each agent tackles different components while maintaining full context awareness, eliminating manual debugging bottlenecks and accelerating feature delivery.[Discover Verdent AI(Free Trial)](https://ads.claudelog.com/https://www.verdent.ai/verdent-deck?ots=claudelog)
![Power up with parallel agents](https://www.claudelog.com/img/ads/sponsors/verdent_ai_horizontal_large_2.png)
See Also:[Model Comparison](https://w

... (truncated to fit token limit)
</details>
</tool-use>

---

Now I have a clear picture. Let me trace through the flow completely to confirm `haiku` works as expected:

**The Flow-Through Analysis:**

1. **Config defines mapping** (`config.py:15-18`):
   ```python
   "/classify_issue": {"base": "haiku", "heavy": "sonnet"}
   ```

2. **Model selection function** (`agent.py:28-59`):
   - `get_model_for_slash_command()` looks up the command in `SLASH_COMMAND_MODEL_MAP`
   - Returns `"haiku"` when `model_set="base"` for `/classify_issue`

3. **Template execution** (`agent.py:509-510`):
   ```python
   mapped_model = get_model_for_slash_command(request)  # → "haiku"
   request = request.model_copy(update={"model": mapped_model})
   ```

4. **CLI command building** (`agent.py:302-303`):
   ```python
   cmd = [CLAUDE_PATH, "-p", request.prompt]
   cmd.extend(["--model", request.model])  # → "--model", "haiku"
   ```

5. **Claude CLI accepts `haiku`** (confirmed from Exa docs):
   - `haiku` is a valid **model alias** that maps to the latest Haiku model
   - The CLI accepts aliases: `sonnet`, `opus`, `haiku`, `opusplan`, `default`

**✅ No functionality is missing.** The flow-through is complete:
- `"haiku"` in the map → `get_model_for_slash_command()` returns `"haiku"` → passed to `--model haiku` CLI flag → Claude CLI accepts it as a valid alias.

**One inconsistency noticed:** In `health.py:150` the full model name `claude-3-5-haiku-20241022` is used directly, while the rest of the codebase uses the shorthand `haiku`. Both work, but the shorthand is cleaner and future-proof (alias automatically points to latest).

**Confirmed working:** The tests in `tests/unit/test_agent.py` and `tests/test_model_selection.py` specifically test the haiku mapping at lines 49-50:
```python
assert SLASH_COMMAND_MODEL_MAP["/classify_issue"]["base"] == "haiku"
```

---

_**User (2025-12-30 04:52Z)**_

opusplan --- what is this>?

---

_**Agent (model claude-4.5-opus-high-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user is asking about "opusplan" - this is a model alias from the Claude CLI documentation I just retrieved. Let me explain what it is based on that documentation.</details></think>

---

Based on the Claude Code docs I just retrieved:

**`opusplan`** is a special model alias that provides an **automated hybrid approach**:

- **In plan mode** → Uses `opus` for complex reasoning and architecture decisions
- **In execution mode** → Automatically switches to `sonnet` for code generation and implementation

It gives you the best of both worlds: Opus's superior reasoning for planning, and Sonnet's efficiency/speed for execution.

**How it works with Claude CLI:**
```bash
claude --model opusplan
```

**Relevance to ADW:** Your current `SLASH_COMMAND_MODEL_MAP` manually achieves something similar by mapping different commands to different models:

```15:35:adw/core/config.py
SLASH_COMMAND_MODEL_MAP: Final[Dict[SlashCommand, Dict[ModelSet, str]]] = {
    "/classify_issue": {"base": "haiku", "heavy": "sonnet"},  # Fast model for simple classification
    ...
    "/implement": {"base": "sonnet", "heavy": "opus"},  # Heavy work gets opus
    "/feature": {"base": "sonnet", "heavy": "opus"},    # Planning gets opus in heavy mode
```

The difference:
- **ADW approach**: You explicitly control model per-command at the orchestration level
- **`opusplan`**: Claude CLI handles plan/execute switching internally within a single session

Your approach is more granular since you can assign different models to different workflow stages (`/classify_issue` → haiku, `/implement` → opus, etc.), whereas `opusplan` is a single-session toggle based on Claude's internal "plan mode" detection.

---

_**User (2025-12-30 04:52Z)**_

One inconsistency noticed: In health.py:150 the full model name claude-3-5-haiku-20241022 is used directly, while the rest of the codebase uses the shorthand haiku. Both work, but the shorthand is cleaner and future-proof (alias automatically points to latest). 

fix it.

---

_**Agent (model claude-4.5-opus-high-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user wants me to fix the inconsistency in health.py where the full model name is used instead of the shorthand "haiku". Let me read the health.py file to see the context and make the fix.</details></think>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: /Users/dev3/code4b/adw-framework/adw/core/health.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** • Read file: /Users/dev3/code4b/adw-framework/tests/health_check.py</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Found the two places that need fixing:
1. `adw/core/health.py` line 150
2. `tests/health_check.py` line 176

I'll fix both to use the shorthand "haiku" instead of the full model name.</details></think>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **search_replace** • Edit file: /Users/dev3/code4b/adw-framework/adw/core/health.py</summary>

**Chunk 1**
Lines added: 1, lines removed: 1

```diff
@@ -148,5 +148,5 @@
              test_prompt,
              "--model",
-             "claude-3-5-haiku-20241022",
+             "haiku",
              "--output-format",
              "stream-json",
```

</details>

</tool-use>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **search_replace** • Edit file: /Users/dev3/code4b/adw-framework/tests/health_check.py</summary>

**Chunk 1**
Lines added: 1, lines removed: 1

```diff
@@ -174,5 +174,5 @@
              test_prompt,
              "--model",
-             "claude-3-5-haiku-20241022",
+             "haiku",
              "--output-format",
              "stream-json",
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Both files have been updated. Let me verify the changes are correct and check for any lint issues.</details></think>

---

<tool-use data-tool-type="shell" data-tool-name="run_terminal_cmd">
<details><summary>Tool use: **run_terminal_cmd** • Run command: cd /Users/dev3/code4b/adw-framework && git diff adw/core/health.py tests/health_check.py</summary>

```bash
cd /Users/dev3/code4b/adw-framework && git diff adw/core/health.py tests/health_check.py
```

```
diff --git a/adw/core/health.py b/adw/core/health.py
index 7991071..ea0c462 100644
--- a/adw/core/health.py
+++ b/adw/core/health.py
@@ -147,7 +147,7 @@ def check_claude_code() -&gt; CheckResult:
             "-p",
             test_prompt,
             "--model",
-            "claude-3-5-haiku-20241022",
+            "haiku",
             "--output-format",
             "stream-json",
             "--verbose",
diff --git a/tests/health_check.py b/tests/health_check.py
index fbf168e..866f41f 100755
--- a/tests/health_check.py
+++ b/tests/health_check.py
@@ -173,7 +173,7 @@ def check_claude_code() -&gt; CheckResult:
             "-p",
             test_prompt,
             "--model",
-            "claude-3-5-haiku-20241022",
+            "haiku",
             "--output-format",
             "stream-json",
             "--verbose",

```
</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
The changes look good. Both files now use the shorthand "haiku" alias instead of the full model name. Let me also commit this change as per the user's instructions to commit regularly.</details></think>

---

Done. Changed `claude-3-5-haiku-20241022` → `haiku` in both:
- `adw/core/health.py:150`
- `tests/health_check.py:176`

The shorthand alias is future-proof—it will automatically point to the latest Haiku model as Anthropic releases updates.

---

